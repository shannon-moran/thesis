\documentclass[11pt]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}
\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{setspace}
\usepackage{cite}
\usepackage{longtable}
\bibliographystyle{unsrt}

% Define useful shortcuts
\def\r{\mathbf{r}}
\def\k{\mathbf{k}}
\def\x{\mathbf{x}}
\def\vv{\mathbf{v}}
\def\F{\mathbf{F}}
\def\D{\mathbf{D}}
\def\T{\mathbf{T}}
\def\z{\mathbf{z}}
\def\etab{\mathbf{\eta}}
\def\Pe{\text{Pe}}

\title{Effective temperature in non-equilibrium systems}
\author{Active Matter sub-group \\ Shannon Moran}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

Why this doc exists: I'm trying to explain the non-equilibrium ``freezing'' and subsequent crystallization I see in my 2D active polygon systems (to borrow language from the literature \cite{BialkeEA_2012_PRL, PalacciEA_2013_Science}). This is by no means meant to be a complete overview, but I hope that writing down what I have found out so far and continuing to update it will be helpful for others looking to go down this literature rabbit hole.


\section{First things first: what is temperature?}

We traditionally approach the definition of temperature in equilibrium systems two ways: through either (1) a kinetic or (2) an entropic lens.

(1) For simple species that we can assume to have elastic collisions, we can think about temperature as a measure of the kinetic energy in the system. As we'll recall from freshman chemistry,
\begin{equation}
T_\text{kinetic} = \frac{2}{3k_B}\langle{E_\text{kinetic}}\rangle
\end{equation}

For simply systems, this works well. However, many of the systems we deal with are more complicated; their internal energy cannot be primarily approximated by kinetic energy due to internal degrees of freedom (e.g. molecular rotation, vibration) or collective modes of a material.

(Note: (1) with some adjustments might actually be a reasonable approximation for temperature in point-disk systems, but I haven't seen an approach using a modified version of this in the literature.)

(2) More generally, then we can think of temperature as a measure of the tendency for of an object to spontaneously give up energy to its surroundings. Just to refresh all of our memories, we define temperature in classical statistical mechanics in the following way:
\begin{equation}
T = \left(\frac{\partial U}{\partial S}\right)_{N,V} = \left(\frac{\partial H}{\partial S}\right)_{N,P}
\end{equation}

Where $U$ is the internal energy, $H$ is the Helmholtz free energy, and $S$ is the entropy.

In active systems, the typical approaches to find an effective temperature leverage definition (2) of temperature. I particularly like the intuition used in Ref. \cite{LoiMossaEA_2008_PRE}, which frames $T_{eff}$ as the additional agitation caused by the nonconservative forces in active systems \cite{LoiMossaEA_2008_PRE}.



\section{Why are we interested in defining an effective temperature in active systems?}

The temperature of the bath the particles are in (plain old $k_BT$ in our systems) drives the magnitude of the thermal fluctuations.

However, active systems are characterized by having a driving force that drives motion and, generally, is $\gg$ than the force of the thermal fluctuations. An effective temperature would allow us to compare the non-equilibrium behavior of the system to the equilibrium thermal fluctuations.

Of interest to our systems, having a defined framework for accounting for the role of various perturbations (...such as shape) in the non-equilibrium behavior of a system would then allow us to quantify the impact of these perturbations/influences.

(Whether temperature is the best method of approaching the issue of the role of shape remains to be seen, and is why this document exists.)



\section{Summary of different approaches to calculating effective temperature in active systems}

Some of the difficulty in calculating an effective temperature comes from the well-documented complications in calculating the thermodynamic properties in active systems \cite{TakatoriEA_2014_PRL, SolonEA_2015_NaturePhysics, SolonEA_2015_PRL, WinklerWysockiGompper_2015_SoftMatter, TakatoriBrady_2015_PRE}. Preisler sums this up well:

\begin{quote}
``... even basic thermodynamic properties such as non-equilibrium equivalents of temperature and pressure depend sensitively on the precise definitions at hand, e.g., the mechanical pressure (force per unit area exerted on a wall), thermodynamic pressure (derivative of the free energy with respect to volume), or hydrodynamic pressure (trace of the bulk stress tensor) do not necessarily correspond to each other in out-of-equilibrium systems, the same is true for various definitions of temperature, e.g. using diffusion, fluctuation- dissipation theorem, and others... there is no consensus on how to define the pressure and temperature in active matter and there is yet no clear statistical mechanics framework for active systems.'' \cite{PreislerDijkstra_2016_SoftMatter}
\end{quote}

With that kind of lead-in, Preisler and Dijkstra then go on to attempt to establish a statistical framework, as does the recent paper on the arxiv by Hancock and Baskaran \cite{HancockBaskaran_2017_arxiv} (in full disclosure, I haven't read this one yet-- ask Chengyu for details). They both seem to use a similar approach of attempting to fit an active matter system to a Boltzmann, and Priesler uses an effective temperature to achieve this.

As people who have been studying this much longer than I have are still disagreeing on the ``best method'' of defining temperature, I'm not going to attempt to do so. However, below are the key few papers for different methods I've seen used. 

\begin{tabular}{| p{4.5in} | p{1in} |}
\hline
\textbf{Approach} & \textbf{References} \\
\hline
Diffusion & \cite{Cates_2012_RepProgPhys} \\
Fluctuation-Dissipation Theorem & \cite{LoiEA_2008_PRE, LoiEA_2011_SoftMatter, WangWolynes_2011_JChemPhys} \\
Tracer particles & \cite{LoiEA_2011_SoftMatter} \\
Tracer particles + active stress & \cite{MarchettiEA_2013_RevModPhys} \\
Configurational entropy & \cite{PreislerDijkstra_2016_SoftMatter} \\
Fitting activity/comparing to [a] Boltzmann distribution at $T_{eff}$ & \cite{PreislerDijkstra_2016_SoftMatter, PaoluzziLeonardoAngelani_2014_JPhysConMat, MaggiEA_2014_PRL} \\
Comparison with glass transition & \cite{BerthierKurchan_2013_NaturePhysics} \\
\hline
\end{tabular}

A few quick notes on what each approach is.

Diffusion
\begin{itemize}
\item I'm including this in the interest of attempted completeness; apparently Michael Cates makes a diffusion-driven argument for a $T_{eff}$ in his review on whether biology needs statistical mechanics. I did not notice this when I read it a while back, so will need to go back and re-read
\end{itemize}

Fluctuation-Dissipation Theorem
\begin{itemize}
\item Generalizing the fluctuation-dissipation theorem to out-of-equilibrium conditions \cite{LoiEA_2011_SoftMatter}, citation 15 in \cite{LoiEA_2011_SoftMatter}
\end{itemize}

Tracer particles
\begin{itemize}
\item ``Temperature should be measurable with a thermometer. A tracer particle with a long internal time scale proportional to the square root of its mass acts as a thermometer that couples to the long-time-delay structural rearrangements and not to the fast vibrations t$\sim$0 which yield the ambient temperature'' \cite{LoiEA_2008_PRE}
\item Using a free tracer particle with mass much larger than one of the polymer beads, whose kinetic energy can be related to the system's effective temperature via an equipartition theorem \cite{LoiEA_2011_SoftMatter}, yield an expression where the $T_{eff}$ is a function of the activity
\end{itemize}

Tracer particles + active stress
\begin{itemize}
\item Apparent temperature can be probed from the motion of a tracer particle and ``can be estimated by the zero-frequency, zero-wave number variance of the active stress''
\item These experiments are put into some more context in the always-helpful Ref \cite{MarchettiEA_2013_RevModPhys}
\end{itemize}

Configurational entropy
\begin{itemize}
\item If we assume entropy is a continuous function of internal (or potential) energy, we can define a potential energy and configurational entropy for the system and use that to find an effective temperature
\item Preisler et al use a density of states argument to find the configurational entropy to then derive a temperature \cite{PreislerDijkstra_2016_SoftMatter}
\end{itemize}

Fitting activity/comparing to [a] Boltzmann distribution at $T_{eff}$
\begin{itemize}
\item Included for attempted completeness
\end{itemize}

Comparison with glass transition
\begin{itemize}
\item Berthier and Kurchan argue that ``dynamic arrest in driven and active materials shares important similarities with the equilibrium glass transition, in particular... the behaviour of time-correlation functions and the emergence of an effective thermal behaviour''
\item Ref \cite{LoiEA_2011_SoftMatter} citations 18-23 are examples of measuring $T_{eff}$ in glassy systems; the argument that the active matter community makes is that very dense systems can be treated like glasses, and therefor similar approaches to develop the effective temperature can be used
\end{itemize}

\section{Side note: Granular materials}
Granular materials are another non-equilibrium system with a wealth of literature attempting to define an ``effective temperature''. These materials are athermal and composed of cohesionless particles. They are ``nonergodic in the extreme sense, as they stay in a single configuration unless driven externally.'' We can think of these as the extreme case of our systems in which we set $T=0$, resulting in a non-Brownian system. Not unlike in an active system without Brownian noise, collective behavior emerges solely as a response to driving forces. In contrast with the types of active systems commonly studied, in which each particle converts its internal energy to a driving force whose direction is often fixed relative to the particle, granular matter is often driven by an \textit{external} force whose direction is fixed relative to the \textit{frame}. \cite{BiEA_2015_AnnRevConMatPhys}

The review cited above is an excellent 2015 overview of this field by Karen Daniels of NC State (who spoke in the Physics department back in the fall). A key topic of her talk was the effective temperature often used in the granular matter community, called the ``compactivity,'' X. 
\begin{equation}
\frac{1}{X} = \frac{\partial S(V)}{\partial V}
\end{equation}
Daniels' talk discussed why this might not be a great temperature stand-in, which is not something I'm going to get into here.

%In one paper cited in \cite{BerthierKurchan_2013_NaturePhysics} studying driven granular fluids, the glass transition shifted towards higher density with increasing activity (drive force). (citation 5)

\begin{singlespacing}
\bibliography{Teff_LitReview}
\end{singlespacing}

\end{document}  






%%%%%%%%%%%% Notes

\section{Background: How true thermodynamic temperature is currently accounted for}
In our Brownian dynamics simulations, we always account for contributions from a (white noise) equilibrium thermal bath at temperature $T$ represented by force $\eta_i(t)$, which satisfies the fluctuation-dissipation theorem (FDT, also called the Nyquist formula), $\langle\eta_i(t)\eta_j(t)\rangle=2T\delta_{ij}$.

The fluctuation-dissipation theorem says that when there is a process that dissipates energy, turning it into heat (e.g., friction), there is a reverse process related to thermal fluctuations. This is best understood by considering some examples: (wikipedia)

Drag and Brownian motion
If an object is moving through a fluid, it experiences drag (air resistance or fluid resistance). Drag dissipates kinetic energy, turning it into heat. The corresponding fluctuation is Brownian motion. An object in a fluid does not sit still, but rather moves around with a small and rapidly-changing velocity, as molecules in the fluid bump into it. Brownian motion converts heat energy into kinetic energy?the reverse of drag. (wikipedia)

In a system of Brownian particles with no active forces, stochastic thermal forces are the only means of particle motion. In the limit of $T\rightarrow0$, the agents do not move (and in our active systems, the only influences on their motion are the active driving force and collisions). In the limit of $T\rightarrow\infty$, the influence of the gradients of the field is almost negligible; hence, agents do not turn to order motion among the nodes, and a network does not occur either. In our active systems, a system with infinite $T$... \cite{Schweitzer_2003}

Particle dynamics may be regarded as an over-damped Langevin dynamics in the low-Reynolds number regime. Mass $m$ is assumed to be negligible such that the translational dynamics for each particle $i$ are given by:
\begin{equation} \label{eq:langevin}
\begin{aligned}
\frac{d\x}{dt} = 0 &= -\gamma_T\frac{d\x}{dt} + F_\text{sp}(t)\vv_\text{sp}(t) + \sum_{j \neq i} \F_{ij}(t) + \F_\text{random,T}(t)
\end{aligned}
\end{equation}
Here, $\gamma_T$ is the friction coefficient and $\vv_\text{sp}(t)$ is the direction of the active force. We assume solvent is implicit in this formulation via $\gamma_T$ (treated as a parameterization of solvent viscosity in the literature) and the stochastic force $\F_\text{random}$. The forces on each particle are given by:
\begin{equation}
\begin{aligned}
F_\text{sp}(t)\vv_\text{sp}(t) &= \text{self-propelled (``active'') force} \\
\sum_{j \neq i} \F_{ij}(t) &= \text{force from inter-particle interactions} \\
\F_\text{random,T}(t) &= \text{random Brownian noise, translational}
\end{aligned}
\end{equation}

In our simulations, the rotational Langevin is analogous to the translational form above, with torques $\T_{ij}$ in place of $\F_{ij}$, no rotational velocity, and a separate noise term.

In the literature, the active force of a self-propelled particle is commonly viewed as a component of the system's dimensionless velocity, given by the active P{\'e}clet number.
\begin{equation}
\Pe = v_p\frac{\tau_T}{\sigma} = \frac{\text{``ballistic energy''}}{\text{``thermal energy''}} = \frac{F_\text{sp}\sigma}{k_BT}
\end{equation}

We see that if Pe is small, diffusion is important, while if Pe is large, directed motion prevails. Thus, we expect to see activity-mediated phenomena at higher Peclet numbers. For our simulations, we set $k_BT=1$ then calculate $F_\text{sp}$ from the Pe set point under study.\footnote{Work out of Michael Cates' group points out that increasing the $F_\text{sp}$ as a means of achieving the desired P{\'e}clet number causes the effective radius of a shape to decrease at high Pe numbers. This occurs because the radius at which the active and repulsive forces balance out will decrease for a constant $\F_\text{random}$ and increasing $F_\text{sp}$, all else being equal. They calculate that the effective rounding radius is decreased by 15\% at Pe=300 in a 3D system \cite{Stenhammar_2014_SoftMatter}. As the typical active 2D parameter space only goes up to Pe=140, the effect of this in our systems should be minimal. However, Suma et al also argue that the active force magnitude must be kept constant to ensure that our assumption of low Reynolds number remains valid (Re$=\frac{mF_\text{sp}}{\gamma^2\sigma}$) \cite{Suma2014}. Both these discussions warrant further investigation, which could be done by comparing results for a phase space varying $k_BT$ instead of $F_\text{sp}$ to achieve Pe, which in turn would necessitate longer simulation times as $\tau$ varies inversely with temperature.}

For disks of diameter $\sigma$, the characteristic diffusion time (that is, the time it takes a particle to diffuse over its length) is $\tau_T = \frac{\sigma^2}{D_T}$, where diffusivity is defined as $D_T=\frac{k_BT}{\gamma_T}$. In active systems, typical values for the integration time step and $\tau$ are approximately ${\Delta}t=10^{-5}$ and $\tau\sim100$, respectively \cite{Prymidis_2016_SoftMatter, Redner_2013_PRL}. Thus, the number of steps for simulation is given by $\frac{100\tau}{{\Delta}t}$. Because $\tau$ varies with $\sigma^2$, the number of steps will increase with particle size.

The force between two particles $i$ and $j$ is given by
\begin{equation}
\F_{ij} = -\frac{\partial U(\r_{ij})}{\partial \r_{ij}}
\end{equation}
As discussed in the previous section, we consider a system of particles with a repulsive force given by the Weeks-Chandler-Anderson (WCA) potential. This is simply a shifted Leonard-Jones (LJ) pair potential so that the potential smoothly goes to 0 at the potential's cut-off radius, $r_\text{cut}$
\begin{equation}
U(r) = \left\{ \begin{aligned}
4{\epsilon}\left[\left(\frac{\sigma}{r}\right)^{12}-\left(\frac{\sigma}{r}\right)^6\right] + {\Delta}V(r) && r<r_\text{cut} \\
0 && r \geq r_\text{cut}
\end{aligned}
\right.
\end{equation}
where $r_\text{cut}=1$ for our simulations and ${\Delta} V(r) = -(r-r_\text{cut})\frac{\partial V_{LJ}}{\partial r}(r_\text{cut})$. Thus, the force exerted on a given particle is the sum of its interactions with all particles that come within $r_\text{cut}$ of the shape.

Finally, if we divide Equation \ref{eq:langevin} by $\gamma_T$, we can rewrite $\frac{\F_\text{random}}{\gamma_T}$ as noise $\etab(t)$. Noise ${\eta}(t)$ is a stationary Gaussian process with zero-mean (white noise), satisfying:
\begin{equation}
\begin{aligned}
\langle \etab(t) \rangle &= 0 \\
\langle \etab(t)\etab(t') \rangle &= 2D_T\delta(t-t')
\end{aligned}
\end{equation}
We see that noise, then, is dependent upon translational diffusivity $D_T$ in the translational Langevin equation and rotational diffusivity $D_R$ in the rotational Langevin equations. Again using the assumption of low Reynolds numbers, we can equate $D_T = \frac{D_R\sigma^2}{3}$. By setting $\gamma_T=1$, we have thus defined the system's translational and rotational noise. 


"From Wikipedia"


%: To-do for this
From marchetti review:
- The nonequilibrium freezing of active particles may be directly relevant to the behavior of suspensions of self-propelled Janus colloids or other artificial microswimmers (Palacci et al., 2010)
- Recent work has demonstrated that active particles do form crystalline states, but the freezing and melting is in this case a true non equilibrium phenomenon that cannot be described simply in terms of an effective temperature for the system (Bialk?e et al., 2012).
- In vitro experiment on confluent monolayers of epithelial cells suggest that the displacement field and stress distribution in these living systems strongly resemble both the dynamical heterogeneities of glasses and the soft modes of jammed packings (Angelini et al., 2010, 2011; Petitjean et al., 2010; Poujade et al., 2007; Trepat et al., 2009).